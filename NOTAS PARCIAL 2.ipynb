{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84468567",
   "metadata": {},
   "source": [
    "# NOTAS PARCIAL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26541d5e",
   "metadata": {},
   "source": [
    "# Regresión Logística\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "La regresión logística es un modelo de clasificación que se utiliza para predecir la probabilidad de que una observación ocurra. Esta probabilidad es una predicción de forma binaria, es decir, existen dos clases que son 0 y 1. 1 significando que el evento ocurre, y 0 que no ocurre. Dependiendo del threshold, si p da mayor a este se considera 1, sino sería 0.\n",
    "\n",
    "**¿CÓMO SE CALCULA?**\n",
    "\n",
    "Tomando en cuenta que p es la probabilidad de que la predicción sea 1, tenemos que: $p = \\frac{1}{1+e^{-z}}$. Esta es la función sigmoide, que convierte los log odds en una probabilidad entre 0 y 1.\n",
    "\n",
    "Luego tenemos que z se calcula de la siguiente manera: $z = \\beta^TX$, donde las betas son los coeficientes de la regresión y X son las características de una observación. Esto nos da como resultado los log odds.\n",
    "\n",
    "**¿PORQUÉ SE UTILIZA LA REGRESIÓN LOGÍSTICA?**\n",
    "\n",
    "La regresión logística se utiliza porque es un modelo fácil de interpretar, ya que su resultado suele ser 0 o 1, dependiendo del threshold que se tenga. Predice la probabilidad de que una observación ocurra. Es decir, se utiliza en situaciones donde se puede clasificar una observación en dos categorías. Por ejemplo, si alguien tiene o no cáncer.\n",
    "\n",
    "**MÁXIMA VEROSIMILITUD Y DESCENSO (ASCENSO) EN GRADIENTE**\n",
    "\n",
    "\n",
    "\n",
    "### Función de Verosimilitud (regresion lineal)\n",
    "\n",
    "\n",
    "Tomando en cuenta un conjunto de datos $(X_i, y_i)$ con \\( i = 1, $\\dots$, m \\), se tiene la siguiente función de verosimilitud. \n",
    "\n",
    "$$\n",
    "L(\\theta, \\sigma^2) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Aquí se puede apreciar que la función de verosimilitud es la multiplicación de probabilidades. \n",
    "\n",
    "Después, se saca el logarítmo de esta función para facilitar los calculos siguientes. \n",
    "\n",
    "$$\n",
    "\\log L(\\theta, \\sigma^2) = \\sum_{i=1}^{m} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "Para poder maximizar el logarítmo de la verosimilitud con respecto a $\\theta$ ** se ignoran los términos constantes, ya que no afectan la optimización. Esto es igual a la función de pérdida para minimizar el error cuadrático. Esto significa que podemos minimizar OLS de la siguiente manera: \n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{m} (y_i - \\theta^T X_i)^2\n",
    "$$\n",
    "\n",
    "Finalmente, se aplica el descenso en gradiente a lo anterior para poder ajustar los coeficientes de manera iterativa y maximizar la verosimilitud. Esto se hace a través derivadas parciales de la función de pérdida para ajustar los valores de theta de manera iterativa y minimizar la función de pérdida, lo que equivale a maximizar la verosimilitud.  \n",
    "\n",
    "______________________________________________________________________\n",
    "\n",
    "\n",
    "### Función de Verosimilitud (regresion logistica)\n",
    "\n",
    "En la regresión logística, para calcular la máxima versimilitud y aplicar el descenso en gradiente, se toma en cuenta que $y_i$ sigue una distribución de Bernouilli y que $\\sigma$ es la función sigmoide. Tomando esto en cuenta, la función de verosimilitud es la siguiente:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Aquí se puede apreciar que la función de verosimilitud es la multiplicación de probabilidades. \n",
    "\n",
    "Después, se saca el logarítmo de esta función para facilitar los calculos siguientes. \n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Después de esto, maximizamos la log-versimilitud, que es nuestra función de pérdida, para así poder estimar theta. \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Aquí se aplica el descenso en gradiente, que en este caso en realidad es ascenso en gradiente debido a la forma que tiene esta función, que es una curva que asciende. \n",
    "\n",
    "Como ya sabemos, con el descenso en gradiente, buscamos minimizar la función de pérdida que se encontró anteriormente. Esto a través del siquiente gradiente con respecto a $\\theta_j$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "Se modifican los thetas con sus valores óptimos, de manera iterativa, hasta que el modelo converga y se minimice la función de pérdida. Cabe mencionar que se toma en cuenta que $\\alpha$ es la tasa de aprendizaje.\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94ed87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8feffea",
   "metadata": {},
   "source": [
    "# Odds y log odds\n",
    "\n",
    "\n",
    "**ODDS**\n",
    "\n",
    "Los odds son la probabilidad que tienes de ganar entre la probabilidad que tienes de perder. \n",
    "\n",
    "Por ejemplo, si mi equipo gana 1 a 4, los odds serían $\\frac{1}{4}$. Para comprobar esto, sería sacar ambas probabilidades y dividirlas. Es decir,\n",
    "\n",
    "**probabilidad de ganar:** $\\frac{1}{1+4} = 0.2$\n",
    "\n",
    "**probabilidad de perder:** $1 - \\frac{1}{1+4} = 0.8$\n",
    "\n",
    "odds: $\\frac{0.2}{0.8}$ = 0.25 = $\\frac{1}{4}$\n",
    "\n",
    "La manera general de los odds sería $odds = \\frac{p}{1-p}$ donde p es la probabilidad de ganar o de que ocurra un evento.\n",
    "\n",
    "\n",
    "**LOG ODDS** \n",
    "\n",
    "Los log odds son utilizados para linealizar los datos y estabilizar la varianza. De manera general, los log odds serían  $logodds = log(\\frac{p}{1-p})$. Se utiliza para poder aplicarlo a modelos como la regresión logística. \n",
    "\n",
    "Cabe mencionar que una regresión logística utiliza log odds. Es decir, tomando en cuenta que p es la probabilidad de que la predicción sea 1, tenemos que: $p = \\frac{1}{1+e^{-z}}$. Esta es la función sigmoide, que convierte los log odds en una probabilidad entre 0 y 1.\n",
    "\n",
    "Luego tenemos que z se calcula de la siguiente manera: $z = \\beta^TX$, donde las betas son los coeficientes de la regresión y X son las características de una observación. Esto nos da como resultado los log odds.  \n",
    "\n",
    "Dependiendo del threshold, si p da mayor a este se clasifica como 1, sino sería 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf86774e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f745719c",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "La función Softmax se utiliza cuando se tienen más de dos clases. Es decir, se utiliza en problemas de clasificación multiclase. Esta función ayuda a predecir la probabilidad de que una observación pertenezca a alguna de las múltiples clases diferentes, asegurando que las probabilidades sumen 1.  \n",
    "\n",
    "#### **Ejemplo Numérico**\n",
    "Si tenemos 3 clases y logits calculados como:\n",
    "$$\n",
    "z_1 = 2.0, \\quad z_2 = 1.0, \\quad z_3 = -1.0\n",
    "$$\n",
    "Aplicamos Softmax:\n",
    "$$\n",
    "P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72\n",
    "$$\n",
    "$$\n",
    "P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26\n",
    "$$\n",
    "$$\n",
    "P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04\n",
    "$$\n",
    "\n",
    "Esto indica que la clase 1 es la más probable.\n",
    "\n",
    "**DIFERENCIA ENTRE SOFTMAX Y FUNCIÓN SIGMOIDE**\n",
    "\n",
    "La función sigmoide se utiliza cuando nomás se tienen dos clases, es decir, cuando se tiene una clasificación binaria (0 y 1). Se convierten los log odds en probabilidades. La función softmax se utiliza cuando hay más de dos clases, es decir, en clasificación multiclase. Se convierten los logits en probabilidades, y se asegura que la suma de estas sea igual a 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972bac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992a94f2",
   "metadata": {},
   "source": [
    "# Análisis del discriminante lineal\n",
    "\n",
    "El análisis del discriminante lineal es un método que se utiliza para clasificar datos en diferentes clases basándose en sus características. Es decir, este método predice a que clase pretenece un dato, tomando en cuenta las probabilidades de que ese dato pertenezca a cada una de las clases.  \n",
    "\n",
    "En el análisis de discriminante lineal se asume que los datos siguen una distribución normal multivariada . La probabilidad de que un dato pertenezca a una clase, basándose en sus características, se hace de la siguiente manera:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Al calcular la probabilidad de que el dato pertenezca a cada una de las clases, se aplica el Teorema de Bayes con la siguiente formula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Con los resultados, se elige la probabilidad más alta y el dato pertenecerá a esa clase. \n",
    "\n",
    "__________________________________\n",
    "\n",
    "Existen dos tipos:\n",
    "\n",
    "1. **GDA con matriz de covarianza compartida**:\n",
    "   - En este caso, todas las clases comparten la misma matriz de covarianza $\\Sigma$. Esto simplifica el modelo y reduce el número de parámetros a estimar.\n",
    "   - La frontera de decisión entre clases es lineal (hiperplano).\n",
    "\n",
    "2. **GDA con matriz de covarianza específica**:\n",
    "   - Cada clase tiene su propia matriz de covarianza $\\Sigma_k$.\n",
    "   - La frontera de decisión entre clases es cuadrática (más flexible pero con más parámetros).\n",
    "   \n",
    "   \n",
    "   \n",
    "## Ventajas:\n",
    "- Es un modelo probabilístico, por lo que proporciona estimaciones de probabilidad.\n",
    "- Funciona bien cuando los datos siguen una distribución aproximadamente gaussiana.\n",
    "- Es eficiente computacionalmente.\n",
    "\n",
    "## Desventajas:\n",
    "- La suposición de normalidad puede no ser válida en todos los casos.\n",
    "- En problemas de alta dimensionalidad, la estimación de la matriz de covarianza puede ser inestable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df8275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e178020",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "Una red neuronal es un tipo de modelo que se utiliza para predecir algo. Esta formada por distintas capas. La capa de entrada es la que recibe los datos, las capas ocultas procesan la información y la capa de salida da el resultado final. Los datos entran a la red neuronal y pasan por las diferentes capas, con distintas neuronas, donde se les aplican distintas transformaciones mediante funciones de activación (como puede ser relu). El modelo luego realiza foward propagation, que es un proceso mediante el cual el modelo toma los datos de entrada y realiza una predicción. En este proceso, en cada neurona de la red, los datos de entrada se multiplican por los pesos W y se  suma un sesgo b. \n",
    "\n",
    "$$\n",
    "z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "a^{[l]} = g(z^{[l]})\n",
    "$$\n",
    "\n",
    "Este resultado pasa por una función de activación, para así realizar una predicción. Al obtener un resultado, el modelo pasa por un proceso de backpropagation. Aquí se calcula el error que se obtuvo a través de la siguiente función de pérdida: \n",
    "\n",
    "$$\n",
    "\\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})\n",
    "$$\n",
    "\n",
    "Desde la última capa hasta la primera capa oculta, se calcula lo siguiente:\n",
    "\n",
    "$$\n",
    "\\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "$$\n",
    "\n",
    "Con esto la red neuronal aprende de los errores de la predicción y así puede ajustar o actualizar los parámetros. \n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "A través de la derivada parcial de la función de pérdida, finalmente se actualizan los pesos hasta obtener la mejor predicción posible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb0972a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6691028f",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "El AUC es una métrica que mide que tan bien un modelo de clasificación distingue entre clases, esto a través de el área bajo la curva ROC. Esta curva muestra la relación entre TP (verdaderos positivos) y FP (falsos positivos) a diferentes umbrales. El AUC va de 0 a 1, entre más cercano sea a 1, mejor es el desempeño del modelo para clasificar clases. Esta métrica es la probabilidad de que las predicciones de la clase positiva (1) sean mayores a las predicciones de la clase negativa (0). Por ejemplo, si tienes las clases de vive o muere, el auc sería la probabilidad de que las predicciones de vive sean mayores que las de muere. \n",
    "\n",
    "**¿PORQUÉ SE UTILIZA?**\n",
    "\n",
    "El AUC se utiliza para evaluar que tan bien un modelo de clasificación distingue entre clases, tomando en cuenta todos los umbrales. Facilita el análisis y entendimiento de las curvas ROC, pudiendo comparar entre modelos cual es el mejor.\n",
    "\n",
    "**SENSITIVITY**\n",
    "\n",
    "El sensitivity es la tasa de predicciones que el modelo tuvo correctas que dan 1. Es decir, si tenemos el ejemplo de vive o muere, sería la tasa de predicciones correctas de los que viven. Se calcula de la siguiente manera:\n",
    "\n",
    "$$\\text{Sensitivity} = \\frac{\\text{True positive (TP)}}{\\text{True positive (TP)} + \\text{False Negative (FN)}}$$\n",
    "\n",
    "\n",
    "**SPECIFICITY**\n",
    "\n",
    "El specificity es la tasa de predicciones que el modelo tuvo correctas que dan 0. Es decir, si tenemos el ejemplo de vive o muere, sería la tasa de predicciones correctas de los que mueren. Se calcula de la siguiente manera:\n",
    "\n",
    "$$\\text{Specificity} = \\frac{\\text{True Negative (TN)}}{\\text{True Negative (TN)} + \\text{False Positive (FP)}}$$\n",
    "\n",
    "Esto también se puede poner como (1- Specificity)\n",
    "\n",
    "**GINI**\n",
    "\n",
    "$Gini = 2 * AUC - 1$ \n",
    "\n",
    "El gini hace que el AUC este entre 0 y 1, para así facilitar su interpretación. Un valor cercano a 1 indica que el modelo hace un buen trabajo distinguiendo entre clases, mientras que si es cercano a 0 demuestra que el modelo tiene poca habilidad para distinguir entre clases. \n",
    "\n",
    "**¿PORQUÉ SE CAMBIARÍA EL THRESHOLD?**\n",
    "\n",
    "El threshold se puede llegar a cambiar dependiendo de tu meta. Es decir, si te importa más clasificar de manera más correcta los 1 o los 0. EJEMPLO OBESIDAD O EJEMPLO VIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c3bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
