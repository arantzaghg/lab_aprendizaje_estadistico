{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84468567",
   "metadata": {},
   "source": [
    "# NOTAS PARCIAL 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26541d5e",
   "metadata": {},
   "source": [
    "# Regresión Logística\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "La regresión logística es un modelo de clasificación que se utiliza para predecir la probabilidad de que una observación ocurra. Esta probabilidad es una predicción de forma binaria, es decir, existen dos clases que son 0 y 1. 1 significando que el evento ocurre, y 0 que no ocurre. Dependiendo del threshold, si p da mayor a este se considera 1, sino sería 0.\n",
    "\n",
    "**¿CÓMO SE CALCULA?**\n",
    "\n",
    "Tomando en cuenta que p es la probabilidad de que la predicción sea 1, tenemos que: $p = \\frac{1}{1+e^{-z}}$. Esta es la función sigmoide, que convierte los log odds en una probabilidad entre 0 y 1.\n",
    "\n",
    "Luego tenemos que z se calcula de la siguiente manera: $z = \\beta^TX$, donde las betas son los coeficientes de la regresión y X son las características de una observación. Esto nos da como resultado los log odds.\n",
    "\n",
    "**¿PORQUÉ SE UTILIZA LA REGRESIÓN LOGÍSTICA?**\n",
    "\n",
    "La regresión logística se utiliza porque es un modelo fácil de interpretar, ya que su resultado suele ser 0 o 1, dependiendo del threshold que se tenga. Predice la probabilidad de que una observación ocurra. Es decir, se utiliza en situaciones donde se puede clasificar una observación en dos categorías. Por ejemplo, si alguien tiene o no cáncer.\n",
    "\n",
    "**MÁXIMA VEROSIMILITUD Y DESCENSO (ASCENSO) EN GRADIENTE**\n",
    "\n",
    "\n",
    "\n",
    "### Función de Verosimilitud (regresion lineal)\n",
    "\n",
    "Multiplicar probabilidades y se asume que siguen una distribucion normal\n",
    "\n",
    "Dado un conjunto de datos $(X_i, y_i)$ con \\( i = 1, $\\dots$, m \\), la *función de verosimilitud* es:\n",
    "\n",
    "$$\n",
    "L(\\theta, \\sigma^2) = \\prod_{i=1}^{m} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\\right)\n",
    "$$\n",
    "\n",
    "Tomamos el *logaritmo de la verosimilitud*:\n",
    "\n",
    "$$\n",
    "\\log L(\\theta, \\sigma^2) = \\sum_{i=1}^{m} \\left( -\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "### *Relación con OLS*  \n",
    "\n",
    "Para **maximizar la verosimilitud respecto a $\\theta$ **, ignoramos términos constantes:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta} \\sum_{i=1}^{m} -\\frac{(y_i - \\theta^T X_i)^2}{2\\sigma^2}\n",
    "$$\n",
    "\n",
    "Esto equivale a *minimizar el error cuadrático*:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\sum_{i=1}^{m} (y_i - \\theta^T X_i)^2\n",
    "$$\n",
    "\n",
    "\n",
    "*Conclusión:* Minimizar el error cuadrático con *OLS* es lo mismo que *maximizar la verosimilitud* bajo una *distribución normal de los errores*.\n",
    "\n",
    "\n",
    "### Función de Verosimilitud (regresion logistica)\n",
    "\n",
    "En la regresión logística, para calcular la máxima versimilitud y aplicar el descenso en gradiente, se toma en cuenta que $y_i$ sigue una distribución de Bernouilli y que $\\sigma$ es la función sigmoide. Tomando esto en cuenta, la función de verosimilitud es la siguiente:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Aquí se puede apreciar que la función de verosimilitud es la multiplicación de probabilidades. \n",
    "\n",
    "Después, se saca el logarítmo de esta función para facilitar los calculos siguientes. \n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Después de esto, maximizamos la log-versimilitud, que es nuestra función de pérdida, para así poder estimar theta. \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Aquí se aplica el descenso en gradiente, que en este caso en realidad es ascenso en gradiente debido a la forma que tiene esta función, que es una curva que asciende. \n",
    "\n",
    "Como ya sabemos, con el descenso en gradiente, buscamos minimizar la función de pérdida que se encontró anteriormente. Esto a través del siquiente gradiente con respecto a $\\theta_j$.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "Se modifican los thetas con sus valores óptimos, de manera iterativa, hasta que el modelo converga y se minimice la función de pérdida. Cabe mencionar que se toma en cuenta que $\\alpha$ es la tasa de aprendizaje.\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ec780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8feffea",
   "metadata": {},
   "source": [
    "# Odds y log odds\n",
    "\n",
    "\n",
    "**ODDS**\n",
    "\n",
    "Los odds son la probabilidad que tienes de ganar entre la probabilidad que tienes de perder. \n",
    "\n",
    "Por ejemplo, si mi equipo gana 1 a 4, los odds serían $\\frac{1}{4}$. Para comprobar esto, sería sacar ambas probabilidades y dividirlas. Es decir,\n",
    "\n",
    "**probabilidad de ganar:** $\\frac{1}{1+4} = 0.2$\n",
    "\n",
    "**probabilidad de perder:** $1 - \\frac{1}{1+4} = 0.8$\n",
    "\n",
    "odds: $\\frac{0.2}{0.8}$ = 0.25 = $\\frac{1}{4}$\n",
    "\n",
    "La manera general de los odds sería $odds = \\frac{p}{1-p}$ donde p es la probabilidad de ganar o de que ocurra un evento.\n",
    "\n",
    "\n",
    "**LOG ODDS** \n",
    "\n",
    "Los log odds son utilizados para linealizar los datos y estabilizar la varianza. De manera general, los log odds serían  $logodds = log(\\frac{p}{1-p})$. Se utiliza para poder aplicarlo a modelos como la regresión logística. \n",
    "\n",
    "Cabe mencionar que una regresión logística utiliza log odds. Es decir, tomando en cuenta que p es la probabilidad de que la predicción sea 1, tenemos que: $p = \\frac{1}{1+e^{-z}}$. Esta es la función sigmoide, que convierte los log odds en una probabilidad entre 0 y 1.\n",
    "\n",
    "Luego tenemos que z se calcula de la siguiente manera: $z = \\beta^TX$, donde las betas son los coeficientes de la regresión y X son las características de una observación. Esto nos da como resultado los log odds.  \n",
    "\n",
    "Dependiendo del threshold, si p da mayor a este se clasifica como 1, sino sería 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdde1ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f745719c",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "La función Softmax se utiliza cuando se tienen más de dos clases. Es decir, se utiliza en problemas de clasificación multiclase. Esta función ayuda a predecir la probabilidad de que una observación pertenezca a alguna de las múltiples clases diferentes, asegurando que las probabilidades sumen 1.  \n",
    "\n",
    "#### **Ejemplo Numérico**\n",
    "Si tenemos 3 clases y logits calculados como:\n",
    "$$\n",
    "z_1 = 2.0, \\quad z_2 = 1.0, \\quad z_3 = -1.0\n",
    "$$\n",
    "Aplicamos Softmax:\n",
    "$$\n",
    "P(y=1) = \\frac{e^2}{e^2 + e^1 + e^{-1}} = 0.72\n",
    "$$\n",
    "$$\n",
    "P(y=2) = \\frac{e^1}{e^2 + e^1 + e^{-1}} = 0.26\n",
    "$$\n",
    "$$\n",
    "P(y=3) = \\frac{e^{-1}}{e^2 + e^1 + e^{-1}} = 0.04\n",
    "$$\n",
    "\n",
    "Esto indica que la clase 1 es la más probable.\n",
    "\n",
    "**DIFERENCIA ENTRE SOFTMAX Y FUNCIÓN SIGMOIDE**\n",
    "\n",
    "La función sigmoide se utiliza cuando nomás se tienen dos clases, es decir, cuando se tiene una clasificación binaria (0 y 1). Se convierten los log odds en probabilidades. La función softmax se utiliza cuando hay más de dos clases, es decir, en clasificación multiclase. Se convierten los logits en probabilidades, y se asegura que la suma de estas sea igual a 1.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd1d79f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992a94f2",
   "metadata": {},
   "source": [
    "# Análisis del discriminante lineal\n",
    "\n",
    "El *Análisis Discriminante Gaussiano* (GDA, por sus siglas en inglés) es un método de clasificación supervisada en el campo del aprendizaje automático y la estadística. Es un modelo probabilístico que asume que los datos de cada clase siguen una distribución normal (gaussiana) y utiliza esta suposición para estimar las probabilidades de pertenencia a cada clase.\n",
    "\n",
    "## Conceptos clave del GDA:\n",
    "\n",
    "1. *Distribución Gaussiana (Normal)*:\n",
    "   - El GDA asume que los datos de cada clase \\( k \\) se distribuyen según una distribución normal multivariada:\n",
    "     $$\n",
    "     P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "     $$\n",
    "     Donde:\n",
    "     - $\\mathbf{x}$ es el vector de características.\n",
    "     - $\\mu_k$ es el vector de medias de la clase \\( k \\).\n",
    "     - $\\Sigma_k$ es la matriz de covarianza de la clase \\( k \\).\n",
    "     - $\\Sigma_k|$ es el determinante de la matriz de covarianza.\n",
    "\n",
    "2. *Clases*:\n",
    "   - El GDA se utiliza para problemas de clasificación en los que las etiquetas $y$ son discretas (por ejemplo, clasificación binaria o multiclase).\n",
    "\n",
    "3. *Probabilidad a priori*:\n",
    "   - El modelo también estima la probabilidad a priori $P(y = k)$ de cada clase, que representa la proporción de datos que pertenecen a la clase $k$.\n",
    "\n",
    "4. *Regla de Bayes*:\n",
    "   - Para clasificar un nuevo punto $\\mathbf{x}$, el GDA utiliza la regla de Bayes para calcular la probabilidad posterior:\n",
    "     $$\n",
    "     P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "     $$\n",
    "     Donde $P(\\mathbf{x})$ es la evidencia (normalización constante).\n",
    "\n",
    "5. *Decisión de clasificación*:\n",
    "   - El punto $\\mathbf{x}$ se asigna a la clase $ k$ que maximiza la probabilidad posterior $P(y = k | \\mathbf{x})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfdd07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e178020",
   "metadata": {},
   "source": [
    "# Redes neuronales\n",
    "\n",
    "Una red neuronal es un tipo de modelo que se utiliza para predecir algo. Esta formada por distintas capas. La capa de entrada es la que recibe los datos, las capas ocultas procesan la información y la capa de salida da el resultado final. Los datos entran a la red neuronal y pasan por las diferentes capas, con distintas neuronas, donde se les aplican distintas transformaciones mediante funciones de activación (como puede ser relu). El modelo luego realiza foward propagation, que es un proceso mediante el cual el modelo toma los datos de entrada y realiza una predicción. En este proceso, en cada neurona de la red, los datos de entrada se multiplican por los pesos W y se  suma un sesgo b. \n",
    "\n",
    "$$\n",
    "z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "a^{[l]} = g(z^{[l]})\n",
    "$$\n",
    "\n",
    "Este resultado pasa por una función de activación, para así realizar una predicción. Al obtener un resultado, el modelo pasa por un proceso de backpropagation. Aquí se calcula el error que se obtuvo a través de la siguiente función de pérdida: \n",
    "\n",
    "$$\n",
    "\\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})\n",
    "$$\n",
    "\n",
    "Desde la última capa hasta la primera capa oculta, se calcula lo siguiente:\n",
    "\n",
    "$$\n",
    "\\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "$$\n",
    "\n",
    "Con esto la red neuronal aprende de los errores de la predicción y así puede ajustar o actualizar los parámetros. \n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "A través de la derivada parcial de la función de pérdida, finalmente se actualizan los pesos hasta obtener la mejor predicción posible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aecdd64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6691028f",
   "metadata": {},
   "source": [
    "# AUC\n",
    "\n",
    "**¿QUÉ ES?**\n",
    "\n",
    "El AUC es una métrica que mide que tan bien un modelo de clasificación distingue entre clases, esto a través de el área bajo la curva ROC. Esta curva muestra la relación entre TP (verdaderos positivos) y FP (falsos positivos) a diferentes umbrales. El AUC va de 0 a 1, entre más cercano sea a 1, mejor es el desempeño del modelo para clasificar clases. En otras palabras, el AUC es la probabilidad de que el verdadero positivo tenga una probabilidad mayor al falso positivo. \n",
    "\n",
    "**tomas a dos personas, uno vive y otro muere, la probabilidad de que el que vive tenga mayor probabilidad comparado con el otro.**\n",
    "\n",
    "**¿PORQUÉ SE UTILIZA?**\n",
    "\n",
    "El AUC se utiliza paraevaluar que tan bien un modelo de clasificación distingue entre clases, tomando en cuenta todos los umbrales. FALTA\n",
    "\n",
    "**SENSITIVITY**\n",
    "\n",
    "\n",
    "**SPECIFICITY**\n",
    "\n",
    "\n",
    "**GINI**\n",
    "\n",
    "$Gini = 2 * AUC - 1$ \n",
    "\n",
    "El gini hace que el AUC este entre 0 y 1, para así facilitar su interpretación. Un valor cercano a 1 indica que el modelo hace un buen trabajo distinguiendo entre clases, mientras que si es cercano a 0 demuestra que el modelo tiene poca habilidad para distinguir entre clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146c3bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
