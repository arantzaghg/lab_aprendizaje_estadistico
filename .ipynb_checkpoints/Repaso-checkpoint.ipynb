{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c819745",
   "metadata": {},
   "source": [
    "# Notas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f80f49",
   "metadata": {},
   "source": [
    "**QUE SIGNIFICA ESTANDARIZAR**\n",
    "\n",
    "**QUE ES FEATURE ENGINEERING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07727624",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8751020",
   "metadata": {},
   "source": [
    "- Cross-validation es cuando los datos se dividen en datos de entrenamiento (train) y de prueba (test) para así entrenar y evaluar el modelo. El objetivo de esto es medir la capacidad del modelo para generalizar el modelo a nueva información y así poder evitar hacer overfitting (que se ajuste de más el modelo a los datos reales) y que no solo se memorice los datos de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8785cce9",
   "metadata": {},
   "source": [
    "### Decenso en gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b350847",
   "metadata": {},
   "source": [
    "**¿Qué es el decenso en gradiente?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f4421",
   "metadata": {},
   "source": [
    "- El descenso en gradiente es un método de optimización donde se busca minimizar una función a través del gradiente (o sea a través de la derivada de la función). En nuestro caso, tenemos la siguiente función de pérdida $L = \\frac{1}{2}\\sum(x_1 B_1 -y)^2$ y su respectiva gráfica que es una parábola concava hacía arriba. Tomando esto en cuenta, se considera que tomas un punto de manera aleatoria en cualquier lado de la gráfica y queremos que el punto se mueva cada vez más cerca al punto mínimo, es decir, donde la pérdida sea practicamente cero. Es decir, se necesita derivar la función y repetirlo hasta converger al punto mínimo, a través de iteraciones del punto. Este proceso nos daría lo siguiente: $B_1 = B - \\alpha \\frac{\\partial L}{\\partial B_1}$. Esta es la función que permite el movimiento del punto a través de la parábola, ya que $B_1$ sería el punto nuevo y es igual al punto anterior menos la tasa de aprendizaje ($\\alpha$) por el gradiente. El que esto sea resta permite que el punto se mueva de lado a lado en la parábola, acercándose cada vez más al punto mínimo. Es importante mencionar que la tasa de aprendizaje es lo que permite que el cambio no sea tan grande"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdb5a36",
   "metadata": {},
   "source": [
    "### Regresiones lineales simples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2631ac",
   "metadata": {},
   "source": [
    "**¿Qué es una regresión lineal simple?**\n",
    "\n",
    "- Una regresión lineal simple es un modelo que nos permite entender la relación que existe entre una variable dependiente y una independiente. Además, nos permite predecir como una variable afecta a la otra mediante una línea recta que se ajusta de cierta manera a los datos reales. \n",
    "- Se utiliza para predecir resultados, identificar relaciones que existen entre variables y para analizar tendencias lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377a783",
   "metadata": {},
   "source": [
    "**¿Qué es Ridge?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495abb5",
   "metadata": {},
   "source": [
    "- Ridge sirve para regularizar y evitar que el modelo se ajuste de más a los datos, es decir que haya overfitting. Además, ayuda que mejorar el rendimiento del modelo. Con Ridge, se reduce el impacto de todas las variables importantes del modelo sin eliminarlas por completo. En otras palabras, Ridge penaliza las betas del modelo sin eliminarlas por completo, esto lo hace sumando el cuadrado  de cada coeficiente. En este caso, si el coeficiente es mayor, su penalización será mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fb5107",
   "metadata": {},
   "source": [
    "**¿Qué es Lasso?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6973d63f",
   "metadata": {},
   "source": [
    "- Lasso sirve para regularizar y evitar que el modelo se ajuste de más a los datos, es decir que haya overfitting. Además, ayuda que mejorar el rendimiento del modelo. Con Lasso, se reduce el impacto de variables menos importantes, eliminadolas por completo, y deja solo las variables más importantes para el modelo. En otras palabras, Lasso penaliza las betas del modelo y puede llegar a eliminar alguna variable. Lasso penaliza sumando el valor absoluto de cada coeficiente, haciendo que algunos coeficientes se hagan cero y se eliminen. (se ignoran variables que no importan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9cfcf3",
   "metadata": {},
   "source": [
    "**¿Cómo se agrega Ridge o Lasso al descenso en gradiente?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd004f2e",
   "metadata": {},
   "source": [
    "- Se le puede agregar Ridge o Lasso al descenso en gradiente de la siguiente manera:\n",
    "\n",
    "Ridge: $L = \\frac{1}{2}\\sum(x_1 B_1 -y)^2 + \\sum B^2$\n",
    "\n",
    "Lasso: $L = \\frac{1}{2}\\sum(x_1 B_1 -y)^2 + \\sum |B|$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cdd1c2",
   "metadata": {},
   "source": [
    "### Regresiones polinomiales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdf9200",
   "metadata": {},
   "source": [
    "**¿Qué es una regresión polinomial?**\n",
    "- Una regresión polinomial es un modelo que analiza la relación entre una variable dependiente y una o más variables independientes, a través de una forma curva. Es decir, a diferencia de la regresión lineal, la regresión polinomial se ajusta a los datos reales con una forma curva, lo cual puede ayudar a tener un mayor ajuste y mayor precisión al momento de predecir. Se obtiene esta forma curva al utilizar una potencia que se le aplica a los coeficientes del modelo.\n",
    "- Se utiliza cuando los datos muestran una tendencia que no es lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ca3b3",
   "metadata": {},
   "source": [
    "### Categorizar variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba60d2f",
   "metadata": {},
   "source": [
    "- El categorizar variables se utiliza cuando tienes una variable categórica, yea sean palabras o variables con cierto orden. Es necesario hacer estas variables dummies para así poder convertirlo a algo numérico y que no importe el orden, para así implementarlo en el modelo. \n",
    "\n",
    "Ejemplos: \n",
    "- Días de la semana: Lunes, martes, etc.\n",
    "- Orden: 0, 1, 2 y 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946286ca",
   "metadata": {},
   "source": [
    "### Prueba de hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1a831c",
   "metadata": {},
   "source": [
    "- tsting: se divide un grupo en dos (A y B), donde A sería el grupo que se mantiene con las mismas condiciones y el grupo B se le aplica el cambio deseado. Esto se hace para probar un cambio. Para saber si el cambio o la prueba es estadísticamente significativo, se debe de hacer una prueba de hipótesis, la cual confirma la Ho o la Ha. Esto tomando en cuenta que Ho es que no es significativo el cambio y la Ha es lo contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165867d",
   "metadata": {},
   "source": [
    "### Análisis bivariados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b0305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd831b47",
   "metadata": {},
   "source": [
    "### Teorema de Frisch-Waugh-Lovell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743e6d5c",
   "metadata": {},
   "source": [
    "El objetivo del Teorema de Frisch-Waugh-Lovell es buscar el efecto causal de alguna de las variables (x) en el modelo de regresión.\n",
    "\n",
    "$$\n",
    "\\hat{y} = B_0 + B_1x_1 + B_2x_2 + B_3x_3\n",
    "$$\n",
    "- Esta ecuación representa el modelo de regresión, donde $x_1$, $x_2$ y $x_3$ son las variables a analizar y $B_1$, $B_2$ y $B_3$ son las betas o coeficientes de cada variable.\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\Theta_0 + \\Theta_2 x_2 + \\Theta_3 x_3\n",
    "$$\n",
    "- Para analizar la causalidad de la variable $x_1$, se debe hacer un modelo de regresión donde no se incluye esta variable. Es decir, se hace una predicción sin incluir esta variable para saber lo que se explica con $x_2$ y $x_3$.\n",
    "\n",
    "$$\n",
    "y - \\hat{y} = \\text{residuales de } y\n",
    "$$\n",
    "- Se hace la resta entre $y$ y $\\hat{y}$ para así obtener los residuales de y. Esto nos da lo que no explica $x_2$ y $x_3$ de $y$, ya que se esta restando la $y$ con la $\\hat{y}$ que es la predicción hecha con $x_2$ y $x_3$.\n",
    "\n",
    "$$\n",
    "\\hat{x}_1 = \\gamma_0 + \\gamma_2 x_2 + \\gamma_3 x_3\n",
    "$$\n",
    "- Se hace otra ecuación donde se busca predecir $x_1$ mediante $x_2$ y $x_3$. Es una segunda regresión lineal ahora para $x_1$\n",
    "\n",
    "$$\n",
    "x_1 - \\hat{x}_1 = \\text{residuales de } x\n",
    "$$\n",
    "- Al hacer la resta de $x_1$ y $\\hat{x}_1$, obtenemos lo que $x_2$ y $x_3$ no lograron explicar de $x_1$. Esto se pone como residuales de x\n",
    "\n",
    "$$\n",
    "(y - \\hat{y}) = B_1(x - \\hat{x})\n",
    "$$\n",
    "- Por último, se hace una regresión de los residuales de y contra los residuales de x. Con esto se obtiene el valor de $B_1$, el cual debe de ser igual al $B_1$ original. Esto nos da el efecto causal que tiene la variable $x_1$ sobre el modelo de regresión inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbd396e",
   "metadata": {},
   "source": [
    "### R2 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f697594",
   "metadata": {},
   "source": [
    "**¿Qué es el R2 score?**\n",
    "\n",
    "- El R2 Score es una métrica que nos permite saber el porcentaje de la variación de los datos que se explica con un modelo. Es decir, entre más cercano sea el valor a 1, el modelo tiene una mayor precisión al ajustarse a los datos reales. Si el valor del R2 score es lejano a 1, nos indica que el modelo no hace un buen trabajo al ajustarse a los datos y no tiene una buena precisión. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b15ac8c",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bae0132",
   "metadata": {},
   "source": [
    "**¿Qué es KNN?**\n",
    "- KNN (K Nearest Neighbors) es una algorítmo de machine learning que se utiliza para clasificaciones y regresiones. En el caso de regresiones, se busca predecir el valor de un punto en una gráfica, utilizando las distancias euclidianas se elige una cantidad óptima (K) de vecinos cercanos para calcular el promedio de sus valores y obtener el valor de la predicción. Por otro lado, en el caso de clasificaciones, se utiliza el KNN para elegir los K vecinos más cercanos, se predice la clase más común entre ellos y se le asigna al punto. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f026da0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
