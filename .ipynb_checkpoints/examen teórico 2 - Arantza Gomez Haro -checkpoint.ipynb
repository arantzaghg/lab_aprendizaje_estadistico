{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58182883-edf4-410e-9fb5-3cc408d49dfb",
   "metadata": {},
   "source": [
    "# Examen modulo 2\n",
    "\n",
    "\n",
    "## **Sección 1: Regresión Logística** (30 puntos)  \n",
    "\n",
    "1. **(10 pts)** Explica la diferencia entre la regresión logística **lineal** y la **polinomial**. ¿En qué casos es recomendable usar la versión polinomial?  \n",
    "\n",
    "La regresión logística lineal, es aquella donde se busca clasificar entre dos clases y los datos cuentan con características lineales. Es decir, al igual que en la regresión lineal, al graficar los datos, se puede apreciar linealidad en los datos. Dicho esto, la regresión logística polinomial se utiliza con datos que demuestran curvas o no linealidad. Es decir, la regresión logística lineal debe utilizarse en casos donde los datos son lineales y la polinomial debe utilizarse en casos donde existen distintos patrones, tendencias o curvas, no se asume linealidad.\n",
    "\n",
    "______________\n",
    "\n",
    "2. **(10 pts)** Explica como mediante decenso en gradiente y maxima verosimilitud creamos una regresión lógisitca \n",
    "\n",
    "En la regresión logística, para calcular la máxima versimilitud y aplicar el descenso en gradiente, se toma en cuenta que $y_i$ sigue una distribución de Bernouilli y que sigma es la función sigmoide. Tomando esto en cuenta, la función de verosimilitud es la siguiente:\n",
    "\n",
    "$$\n",
    "L(\\theta) = \\prod_{i=1}^{m} p(y_i | X_i; \\theta) = \\prod_{i=1}^{m} \\left[ \\sigma(\\theta^T X_i) \\right]^{y_i} \\cdot \\left[ 1 - \\sigma(\\theta^T X_i) \\right]^{(1 - y_i)}\n",
    "$$\n",
    "\n",
    "Aquí se puede apreciar que la función de verosimilitud es la multiplicación de probabilidades. \n",
    "\n",
    "Después, se saca el logarítmo de esta función para facilitar los calculos siguientes. \n",
    "\n",
    "$$\n",
    "\\log L(\\theta) = \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Después de esto, maximizamos la log-versimilitud, que es nuestra función de pérdida, para así poder estimar theta. \n",
    "\n",
    "$$\n",
    "J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} \\left[ y_i \\log \\sigma(\\theta^T X_i) + (1 - y_i) \\log (1 - \\sigma(\\theta^T X_i)) \\right]\n",
    "$$\n",
    "\n",
    "Aquí se aplica el descenso en gradiente, que en este caso en realidad es ascenso en gradiente debido a la forma que tiene esta función, que es una curva que asciende. \n",
    "\n",
    "Como ya sabemos, con el descenso en gradiente, buscamos minimizar la función de pérdida que se encontró anteriormente. Esto a través del siguiente gradiente con respecto a theta. \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "Se modifican los thetas con sus valores óptimos, de manera iterativa, hasta que el modelo converga y se minimice la función de pérdida. Cabe mencionar que se toma en cuenta que alpha es la tasa de aprendizaje.\n",
    "\n",
    "$$\n",
    "\\theta_j := \\theta_j + \\alpha \\cdot \\frac{1}{m} \\sum_{i=1}^{m} \\left( \\sigma(\\theta^T X_i) - y_i \\right) X_{ij}\n",
    "$$\n",
    "\n",
    "--------------------------------\n",
    "\n",
    "3. **(10 pts)** Explica el concepto de **odds** y **log-odds** en regresión logística. ¿Por qué la regresión logística predice el **log-odds** en lugar de la probabilidad directamente? Justifica esto   \n",
    "\n",
    "Los odds son la probabilidad que tienes de ganar entre la probabilidad que tienes de perder. \n",
    "\n",
    "Por ejemplo, si mi equipo gana 1 a 4, los odds serían $\\frac{1}{4}$. Para comprobar esto, sería sacar ambas probabilidades y dividirlas. Es decir,\n",
    "\n",
    "probabilidad de ganar: $\\frac{1}{1+4} = 0.2$\n",
    "\n",
    "probabilidad de perder: $1 - \\frac{1}{1+4} = 0.8$\n",
    "\n",
    "odds: $\\frac{0.2}{0.8}$ = 0.25 = $\\frac{1}{4}$\n",
    "\n",
    "La manera general de los odds sería $odds = \\frac{p}{1-p}$ donde p es la probabilidad de ganar o de que ocurra un evento.\n",
    "\n",
    "Por otro lado, los log odds son utilizados para linealizar los datos y estabilizar la varianza. De manera general, los log odds serían  $logodds = log(\\frac{p}{1-p})$. Se utiliza para poder aplicarlo a modelos como la regresión logística. \n",
    "\n",
    "Cabe mencionar que una regresión logística utiliza log odds. Es decir, tomando en cuenta que p es la probabilidad de que la predicción sea 1, tenemos que: $p = \\frac{1}{1+e^{-z}}$. Esta es la función sigmoide, que convierte los log odds en una probabilidad entre 0 y 1. \n",
    "\n",
    "Luego tenemos que z se calcula de la siguiente manera: $z = \\beta^TX$, donde las betas son los coeficientes de la regresión y X son las características de una observación. Esto nos da como resultado los log odds. \n",
    "\n",
    "Dependiendo del threshold, si p da mayor a este se clasifica como 1, sino sería 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38687b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb26f681",
   "metadata": {},
   "source": [
    "## **Sección 2: Área Bajo la Curva (AUC)** (20 puntos)  \n",
    "\n",
    "7. **(5 pts)** Define la **curva ROC** y el AUC. ¿Qué tiene de especial\n",
    "\n",
    "El AUC es una métrica que mide que tan bien un modelo de clasificación distingue entre clases, esto a través de el área bajo la curva ROC. Esta curva muestra la relación entre TP (verdaderos positivos) y FP (falsos positivos) a diferentes umbrales. El AUC va de 0 a 1, entre más cercano sea a 1, mejor es el desempeño del modelo para clasificar clases. Esta métrica es la probabilidad de que las predicciones de la clase positiva (1) sean mayores a las predicciones de la clase negativa (0). Por ejemplo, si tienes las clases de vive o muere, el auc sería la probabilidad de que las predicciones de vive sean mayores que las de muere.\n",
    "\n",
    "------------\n",
    "\n",
    "8. **(5 pts)** Cuando hacemos una curva ROC, siempre ponemos una diagonal, explica que es esa diagonal  \n",
    "\n",
    "Cuando se hace una curva ROC, se pone una línea diagonal. Esta línea nos demuestra la unión de dos puntos importantes, que en teoría son (0,0) y (1,1), tomando en cuenta que los ejes son sensitivity y 1-specificity. En este caso, (0,0) es donde el modelo falla al clasificar, es decir, predice la clase de manera totalmente incorrecta. (1,1) es donde el modelo clasifica de manera correcta la clase. Dicho esto, el modelo no debe de ser similar o cercano a esta diagonal, ya que el modelo no sería óptimo ni correcto al predecir clases, ya que puede fallar o clasificar correctamente, ninguno tiene mayor probabilidad de ocurrir.\n",
    "\n",
    "___________\n",
    "\n",
    "\n",
    "9. **(5 pts)** Un modelo tiene un **AUC de 0.85**. Explica qué significa esto en términos de su capacidad de clasificación. \n",
    "\n",
    "Si un modelo tiene un AUC de 0.85, significaría que el modelo tiene una alta capacidad de clasificación de clases. Es decir, tomando el ejemplo de si una persona vive o muere en el titanic, si este modelo fuera a predecir esto, es muy probable que la predicción dada sea correcta, con un 85% de probabilidad.\n",
    "\n",
    "-----------\n",
    "\n",
    "10. **(5 pts)** Un modelo tiene accuracy de 99% pero AUC de 0.5%, ¿Cómo es que esto podría suceder?\n",
    "\n",
    "Un modelo que tenga un accuracy de 99% demuestra un modelo que tiene una muy alta capacidad de predecir, pero no necesariamente significa que sabe clasificar entre distintas clases. Aquí es donde entra el AUC de 0.5%. Este AUC es muy bajo, indicando que el modelo no clasifica correctamente entre clases. Esto puede ser debido al threshold que se tiene. Es decir, este es esencial para darle mayor importancia a clasificar de manera más correcta los 1 o los 0. Además, se debe considerar la cantidad de datos que se tienen. Aunque el modelo sea bueno para predecir, si los datos mayormente caen en una sola clase, le será dificil al modelo atinarle cuando el dato cae en la clase opuesta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa834e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4760e1f3",
   "metadata": {},
   "source": [
    "## **Sección 3: Análisis del Discriminante Lineal (LDA)** (10 puntos)  \n",
    "\n",
    "11. **(10 pts)** ¿Qué es el análisis del discriminante lineal? ¿En que casos lo usarías? (gausiano)\n",
    "\n",
    "El análisis del discriminante lineal (gausiano) es un método que se utiliza para clasificar datos en diferentes clases basándose en sus características. Es decir, este método predice a que clase pretenece un dato, tomando en cuenta las probabilidades de que ese dato pertenezca a cada una de las clases.  \n",
    "\n",
    "En el análisis de discriminante lineal se asume que los datos siguen una distribución normal multivariada. La probabilidad de que un dato pertenezca a una clase, basándose en sus características, se hace de la siguiente manera:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x} | y = k) = \\frac{1}{(2\\pi)^{n/2}|\\Sigma_k|^{1/2}} \\exp\\left(-\\frac{1}{2}(\\mathbf{x} - \\mu_k)^T \\Sigma_k^{-1} (\\mathbf{x} - \\mu_k)\\right)\n",
    "$$\n",
    "\n",
    "Al calcular la probabilidad de que el dato pertenezca a cada una de las clases, se aplica el Teorema de Bayes con la siguiente formula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{P(\\mathbf{x} | y = k) P(y = k)}{P(\\mathbf{x})}\n",
    "$$\n",
    "\n",
    "Con los resultados, se elige la probabilidad más alta y el dato pertenecerá a esa clase. \n",
    "\n",
    "Este método se utiliza cuando se busca clasificar información entre distintas clases. Se usaría en el caso de que los datos sigan una distribución cercano a un gaussiano. Además es fundamental usarlo cuando todas las clases comparten la misma matriz de covarianza o cuando las clases tienen su matriz de covarianza específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ac856",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5888aed5",
   "metadata": {},
   "source": [
    "## Sección 4: Cross validation  (10 puntos)  \n",
    "\n",
    "12. **(10 pts)** ¿Qué es grid search? ¿qué es random search? Explica las diferencias y cuando usarías cada uno \n",
    "\n",
    "El random search tiene un rango establecido y prueba los hiperparámetros de un modelo de manera aleatoria. Es decir, no prueba todos los valores, solamente algunos al azar, y así elige la mejor opción según esos datos. Cabe mencionar que en realidad puede ser que no sea la mejor opción de manera general, ya que no se utiliza toda la información disponible. Dicho esto, el grid search prueba todos los valores e hiperparámetros posibles que tiene un modelo y así encuentra, ahora si, la mejor opción de combinaciones. En general, random search es mejor cuando hay muchos datos y no quieres esperar mucho para una respuesta o poner en riesgo tu computadora, ya que es mucho más facil de correr.  Por otro lado, grid search funciona de mejor manera para poca cantidad de hiperparámetros e información. Esto es debido a que puede ser muy tardado y depende mucho del poder de la computador para poder realizarse. Además, suele tener mayor precisión dado que usa toda la información.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232deb77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f136fc4",
   "metadata": {},
   "source": [
    "## **Sección 5: Redes Neuronales y Perceptrón Multicapa** (20 puntos)  \n",
    "\n",
    "13. **(5 pts)** Explica que es una red neuronal, que hace, como funciona, etc.   \n",
    " \n",
    "Una red neuronal es un tipo de modelo que se utiliza para predecir algo. Esta formada por distintas capas. La capa de entrada es la que recibe los datos, las capas ocultas procesan la información y la capa de salida da el resultado final. Los datos entran a la red neuronal y pasan por las diferentes capas, con distintas neuronas, donde se les aplican distintas transformaciones mediante funciones de activación (como puede ser relu). El modelo luego realiza foward propagation, que es un proceso mediante el cual el modelo toma los datos de entrada y realiza una predicción. En este proceso, en cada neurona de la red, los datos de entrada se multiplican por los pesos W y se  suma un sesgo b. \n",
    "\n",
    "$$\n",
    "z^{[l]} = W^{[l]}a^{[l-1]} + b^{[l]}\n",
    "$$\n",
    "$$\n",
    "a^{[l]} = g(z^{[l]})\n",
    "$$\n",
    "\n",
    "Este resultado pasa por una función de activación, para así realizar una predicción. Al obtener un resultado, el modelo pasa por un proceso de backpropagation. Aquí se calcula el error que se obtuvo a través de la siguiente función de pérdida: \n",
    "\n",
    "$$\n",
    "\\delta^{[L]} = \\frac{\\partial J}{\\partial z^{[L]}} = (a^{[L]} - y) \\odot g'(z^{[L]})\n",
    "$$\n",
    "\n",
    "Desde la última capa hasta la primera capa oculta, se calcula lo siguiente:\n",
    "\n",
    "$$\n",
    "\\delta^{[l]} = \\left(W^{[l+1]}\\right)^T \\delta^{[l+1]} \\odot g'(z^{[l]})\n",
    "$$\n",
    "\n",
    "Con esto la red neuronal aprende de los errores de la predicción y así puede ajustar o actualizar los parámetros. \n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "A través de la derivada parcial de la función de pérdida, finalmente se actualizan los pesos hasta obtener la mejor predicción posible. \n",
    "\n",
    "----------------------------------------------\n",
    "\n",
    "14. **(5 pts)** ¿Cuál es el propósito de la **backpropagation** en el entrenamiento de redes neuronales?  \n",
    "\n",
    "El propósito del backpropagation es distribuir a todas las neuronas el error obtenido con el foward propagation, para que así el modelo pueda aprender y ajustar los pesos y las transformaciones. Todo esto es con el objetivo de mejorar el resultado final que es la predicción\n",
    "\n",
    "---------\n",
    "\n",
    "15. **(5 pts)** A grandes rasgos, explica como obtenemos los coeficientes de una red neuronal  \n",
    "\n",
    "Los coeficientes de una red neuronal se obtienen a través del proceso de descenso en gradiente y backpropagation. Es decir, tomando en cuenta que con el proceso de backpropagation se obtiene lo siguiente:\n",
    "\n",
    "$$\n",
    "W^{[l]} = W^{[l]} - \\alpha \\frac{\\partial J}{\\partial W^{[l]}}\n",
    "$$\n",
    "$$\n",
    "b^{[l]} = b^{[l]} - \\alpha \\frac{\\partial J}{\\partial b^{[l]}}\n",
    "$$\n",
    "\n",
    "Se deriva parcialmente la función de pérdida y se repite hasta converger y minimizar la funcion de pérdida. Así es como se obtienen los coeficientes, es decir, se ajustan los pesos de manera iterativa para así obtener la mejor predicción y los coeficientes óptimos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496ef50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91bf4701",
   "metadata": {},
   "source": [
    "## **Sección 6: Softmax** (10 puntos)  \n",
    "16. **(5 pts)** Explica que es softmax, para que sirve y como se calcula\n",
    "\n",
    "La función Softmax se utiliza cuando se tienen más de dos clases. Es decir, se utiliza en problemas de clasificación multiclase. Esta función ayuda a predecir la probabilidad de que una observación pertenezca a alguna de las múltiples clases diferentes, dependiendo de que clase sale con la probabilidad más alta, asegurando que las probabilidades sumen 1. \n",
    "\n",
    "Esto se calcula utilizando la siguiente formula:\n",
    "\n",
    "$$\n",
    "P(y = k | \\mathbf{x}) = \\frac{\\exp(\\mathbf{w}_k \\cdot \\mathbf{x} + b_k)}{\\sum_{j=1}^{K} \\exp(\\mathbf{w}_j \\cdot \\mathbf{x} + b_j)}\n",
    "$$\n",
    "\n",
    "Para poder utilizar esta formula, se deben obtener los distintos valores de z. Esto se hace a través de la siguiente formula: \n",
    "\n",
    "$$z = \\theta^TX$$\n",
    "\n",
    "Cabe mencionar que esto se debe hacer para cada clase. Tras esto, se puede utilizar la formula mencionada anteriormente para calcular las probabilidades de pertenencia a cada clase. Con esto, se puede decidir a que clase pertenece el dato analizado. Por ejemplo, si se tienen 3 clases, la primera con una probabilidad de 0.6, la segunda con 0.1 y la tercera con 0.3, el dato se asignará a la clase 1 porque es la probabilidad mayor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5084d0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
